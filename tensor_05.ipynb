{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensor_05.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPB33bGPkj4K6zLQMIQfTw6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sezerblt/data01/blob/master/tensor_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBVHd5jAKkoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use seaborn for pairplot\n",
        "!pip install -q seaborn\n",
        "\n",
        "# Use some functions from tensorflow_docs\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling\n",
        "\n",
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
        "dataset_path\n",
        "\n",
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "dataset.tail()\n",
        "\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
        "\n",
        "dataset = pd.get_dummies(dataset, prefix='', prefix_sep='')\n",
        "dataset.tail()\n",
        "\n",
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "\n",
        "sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\")\n",
        "\n",
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"MPG\")\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats\n",
        "\n",
        "train_labels = train_dataset.pop('MPG')\n",
        "test_labels = test_dataset.pop('MPG')\n",
        "\n",
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)\n",
        "\n",
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()\n",
        "\n",
        "example_batch = normed_train_data[:10]\n",
        "example_result = model.predict(example_batch)\n",
        "example_result\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[tfdocs.modeling.EpochDots()])\n",
        "\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()\n",
        "\n",
        "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n",
        "\n",
        "plotter.plot({'Basic': history}, metric = \"mae\")\n",
        "plt.ylim([0, 10])\n",
        "plt.ylabel('MAE [MPG]')\n",
        "\n",
        "plotter.plot({'Basic': history}, metric = \"mse\")\n",
        "plt.ylim([0, 20])\n",
        "plt.ylabel('MSE [MPG^2]')\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "early_history = model.fit(normed_train_data, train_labels, \n",
        "                    epochs=EPOCHS, validation_split = 0.2, verbose=0, \n",
        "                    callbacks=[early_stop, tfdocs.modeling.EpochDots()])\n",
        "\n",
        "plotter.plot({'Early Stopping': early_history}, metric = \"mae\")\n",
        "plt.ylim([0, 10])\n",
        "plt.ylabel('MAE [MPG]')\n",
        "\n",
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))\n",
        "\n",
        "test_predictions = model.predict(normed_test_data).flatten()\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "lims = [0, 50]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)\n",
        "\n",
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [MPG]\")\n",
        "_ = plt.ylabel(\"Count\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DpE0N5sKzP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}