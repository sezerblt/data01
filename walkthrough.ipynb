{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "walkthrough.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNppAelOUcDEcpu9ElCJM6X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sezerblt/data01/blob/master/walkthrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHR_8zznpk7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
        "\n",
        "#dataları indirme islemi\n",
        "train_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
        "\n",
        "train_dataset_fp = tf.keras.utils.get_file( fname=os.path.basename(train_dataset_url),origin=train_dataset_url )\n",
        "\n",
        "print(\"Dataset dosyası: {}\".format(train_dataset_fp))\n",
        "\n",
        "#gözat\n",
        "# column order in CSV file\n",
        "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
        "\n",
        "feature_names = column_names[:-1]\n",
        "label_name = column_names[-1]\n",
        "\n",
        "print(\"Ozellikler: {}\".format(feature_names))\n",
        "print(\"Etiket: {}\".format(label_name))\n",
        "\n",
        "class_names = ['Iris setosa', 'Iris versicolor', 'Iris virginica']\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = tf.data.experimental.make_csv_dataset(\n",
        "    train_dataset_fp,\n",
        "    batch_size,\n",
        "    column_names=column_names,\n",
        "    label_name=label_name,\n",
        "    num_epochs=1)\n",
        "\n",
        "features, labels = next(iter(train_dataset))\n",
        "\n",
        "print(features)\n",
        "\n",
        "plt.scatter(features['petal_length'],\n",
        "            features['sepal_length'],\n",
        "            c=labels,\n",
        "            cmap='viridis')\n",
        "\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.ylabel(\"Sepal length\")\n",
        "plt.show()\n",
        "\n",
        "def pack_features_vector(features, labels):\n",
        "  \"\"\"Pack the features into a single array.\"\"\"\n",
        "  features = tf.stack(list(features.values()), axis=1)\n",
        "  return features, labels\n",
        "\n",
        "train_dataset = train_dataset.map(pack_features_vector)\n",
        "features, labels = next(iter(train_dataset))\n",
        "\n",
        "print(features[:5])\n",
        "#modeli olusturma\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)), \n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(3)\n",
        "])\n",
        "\n",
        "print(\"--------------------\")\n",
        "predictions = model(features)\n",
        "predictions[:5]\n",
        "tf.nn.softmax(predictions[:5])\n",
        "print(\"--------------------\")\n",
        "print(\"Tahminler: {}\".format(tf.argmax(predictions, axis=1)))\n",
        "print(\"Etiketler: {}\".format(labels))\n",
        "print(\"--------------------\")\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "def loss(model, x, y, training):\n",
        "  y_ = model(x, training=training)\n",
        "  return loss_object(y_true=y, y_pred=y_)\n",
        "\n",
        "l = loss(model, features, labels, training=False)\n",
        "print(\"Loss test: {}\".format(l))\n",
        "\n",
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = loss(model, inputs, targets, training=True)\n",
        "  return loss_value, tape.gradient(loss_value, model.trainable_variables)\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "loss_value, grads = grad(model, features, labels)\n",
        "\n",
        "print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\n",
        "                                          loss_value.numpy()))\n",
        "\n",
        "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "print(\"Step: {},         Loss: {}\".format(optimizer.iterations.numpy(),\n",
        "                                          loss(model, features, labels, training=True).numpy()))\n",
        "\n",
        "## Note: Rerunning this cell uses the same model variables\n",
        "\n",
        "# Keep results for plotting\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 201\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "\n",
        "  for x, y in train_dataset:\n",
        "    loss_value, grads = grad(model, x, y)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    epoch_loss_avg(loss_value)\n",
        "    epoch_accuracy(y, model(x, training=True))\n",
        "\n",
        "  # epoch\n",
        "  train_loss_results.append(epoch_loss_avg.result())\n",
        "  train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "  if epoch % 50 == 0:\n",
        "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
        "                                                                epoch_loss_avg.result(),\n",
        "                                                                epoch_accuracy.result()))\n",
        "    \n",
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}